{
  "$schema": "https://opencode.ai/config.json",
  "provider": {
    "glm_vllm": {
      "npm": "@ai-sdk/openai-compatible",
      "name": "OpenAI-compatible vLLM",
      "options": {
        "baseURL": "http://127.0.0.1:8000/v1"
      },
      "models": {
        "/root/model": {
          "name": "GLM 4.7 Flash Heretic (vLLM)",
          "limit": {
            "context": 128000,
            "output": 8192
          },
          "options": {
            "maxTokens": 8192,
            "reasoning": {
              "enabled": false
            }
          }
        }
      }
    }
  },
  "agent": {
    "bridge": {
      "mode": "primary",
      "description": "XMPP bridge agent",
      "model": "glm_vllm//root/model",
      "default": true,
      "permission": "allow",
      "options": {
        "stream": true
      }
    }
  }
}
