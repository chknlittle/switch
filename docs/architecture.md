# Architecture

## Overview

Switch creates a chat-based interface for AI coding assistants. Each conversation session becomes a separate XMPP contact, allowing you to manage multiple concurrent AI conversations from any XMPP client (Conversations, Gajim, Dino, etc.).

The codebase lives at `~/switch`. AI agents working on this project should reference `~/switch/AGENTS.md` for conventions and `~/switch/memory/` for persistent context.

<!-- DIAGRAM:system -->
<!-- (auto-generated by scripts/sync-diagrams.py; edit docs/diagrams/system.mermaid) -->
```mermaid
flowchart LR
    subgraph User["User Devices"]
        Client["XMPP Client<br/>(Conversations, Gajim, etc.)"]
    end

    subgraph Tailnet["Tailscale Network"]
        subgraph DevBox["Development Machine"]
            XMPP["ejabberd<br/>(XMPP Server)"]

            subgraph Orchestrators["Orchestrator Contacts"]
                direction TB
                CC["cc@...<br/>(Claude Code)"]
                OC["oc@...<br/>(OpenCode GLM 4.7)"]
                OCGPT["oc-gpt@...<br/>(OpenCode GPT 5.2)"]
            end

            Sessions["Session Bots<br/>(task-name@...)"]

            subgraph Engines["AI CLIs"]
                direction TB
                OpenCode["OpenCode CLI"]
                Claude["Claude CLI"]
            end
        end
    end

    Client <-->|"Tailscale IP"| XMPP
    XMPP <--> CC
    XMPP <--> OC
    XMPP <--> OCGPT
    XMPP <--> Sessions
    Sessions --> OpenCode
    Sessions --> Claude

    classDef orchestrator fill:#f5f5e8,stroke:#8a7d60,color:#2c2c2c;
    class CC,OC,OCGPT orchestrator;
```
<!-- /DIAGRAM:system -->

<!-- DIAGRAM:session-message-flow -->
<!-- (auto-generated by scripts/sync-diagrams.py; edit docs/diagrams/session-message-flow.mermaid) -->
```mermaid
flowchart TB
  %% Session message flow (readable on GitHub)

  User["User XMPP Client"]
  XMPP["ejabberd (XMPP)"]

  subgraph Orchestrators["Orchestrators"]
    direction TB
    Dispatcher["DispatcherBot\n(src/bots/dispatcher.py)"]
    Manager["SessionManager\n(src/manager.py)"]
    Lifecycle["create/kill\n(src/lifecycle/sessions.py)"]
  end

  subgraph Session["One Session"]
    direction TB
    SessionBot["SessionBot (XMPP adapter)\n(src/bots/session/bot.py)"]
    Inbound["Inbound parse\n(inbound.py)"]
    Typing["Typing keepalive\n(typing.py)"]
    Runtime["[Q] SessionRuntime\n(queue + cancel + run)\n(src/core/session_runtime/runtime.py)"]
    Cancel["[X] cancel_operations\n(drop queued + cancel in-flight)"]
  end

  subgraph Runners["Runners"]
    direction TB
    Registry["create_runner\n(src/runners/registry.py)"]
    Ports["Runner port\n(run + cancel)\n(src/runners/ports.py)"]
    Claude["ClaudeRunner\n(local claude CLI)"]
    OpenCode["OpenCodeRunner\n(server API)"]
  end

  subgraph Storage["Storage"]
    direction TB
    DB["sessions.db\n(src/db.py repos)"]
    AttStore["AttachmentStore\n(src/attachments/store.py)"]
    AttHTTP["Attachments server\n(src/attachments/server.py)"]
  end

  OpenCodeSrv["External OpenCode server"]

  %% XMPP edges
  User <--> XMPP
  XMPP -->|"orchestrator msg"| Dispatcher
  Dispatcher --> Manager --> Lifecycle --> DB

  XMPP -->|"session msg"| SessionBot
  SessionBot --> Inbound
  SessionBot --> Typing
  SessionBot -->|enqueue| Runtime
  Runtime -->|persist| DB

  %% Attachments
  SessionBot -->|download URLs| AttStore -->|serve| AttHTTP

  %% Runner selection
  Runtime -->|dequeue 1| Registry --> Ports
  Ports -->|engine=claude| Claude
  Ports -->|engine=opencode| OpenCode
  OpenCode <--> |HTTP + SSE| OpenCodeSrv

  %% Streaming back
  Claude -->|events: tool/text/result| Runtime
  OpenCode -->|events: tool/text/question/result| Runtime

  %% Back to user
  Runtime -->|replies + meta| SessionBot
  SessionBot -->|XMPP send| XMPP

  %% Cancellation
  SessionBot -.-> Cancel
  Cancel -.->|drop queued| Runtime
  Cancel -.->|Runner cancel| Ports

  classDef cancel stroke:#b00020,stroke-width:2px,fill:#fff5f6,color:#111;
  class Cancel,Runtime cancel;
```
<!-- /DIAGRAM:session-message-flow -->

<!-- DIAGRAM:opencode-runner -->
<!-- (auto-generated by scripts/sync-diagrams.py; edit docs/diagrams/opencode-runner.mermaid) -->
```mermaid
flowchart TB
  %% OpenCodeRunner internals (HTTP + SSE)

  SessionBot["SessionBot (XMPP adapter)\n(src/bots/session/bot.py)"]
  Runtime["SessionRuntime\n(src/core/session_runtime/runtime.py)"]
  Runner["OpenCodeRunner\n(src/runners/opencode/runner.py)"]
  Config["OpenCodeConfig\n(config.py)\nmodel/agent/reasoning\nquestion_callback"]

  Client["OpenCodeClient\n(client.py)\nHTTP requests"]
  Transport["OpenCodeTransport\n(transport.py)\nSSE task + POST task\n[X] cancel -> /abort"]
  Processor["OpenCodeEventProcessor\n(processor.py)\nparse tool/text/question"]
  Pipe["iter_queue_pipeline()\n(pipeline.py)\nsession gating + idle timeout"]

  Server["External OpenCode server\nHTTP + SSE"]

  %% Wiring
  SessionBot -->|answer question-reply| Runtime
  Runtime -->|create_runner engine=opencode| Runner
  Runner --> Config
  Runner --> Client
  Runner --> Transport
  Runner --> Processor
  Runner --> Pipe

  Client <--> |/global/event SSE| Server
  Client -->|POST /session| Server
  Client -->|POST /session/<id>/message| Server
  Transport -.->|POST /session/<id>/abort| Server

  %% Questions loop
  Q["question asked\n(event)"]
  A["ask user + await reply\n(question_callback)"]

  Pipe --> Q --> Runtime
  Runtime -->|question meta| SessionBot
  SessionBot -->|user reply| Runtime
  Runtime --> A --> Client
  Client -->|POST /question/<rid>/reply| Server

  %% Events back
  Pipe -->|events: tool/text/result| Runner --> Runtime

  classDef cancel stroke:#b00020,stroke-width:2px,fill:#fff5f6,color:#111;
  class Transport cancel;
```
<!-- /DIAGRAM:opencode-runner -->

To keep this diagram consistent across docs, update `docs/diagrams/system.mermaid` and run:

```bash
python3 scripts/sync-diagrams.py
```

## Network Topology

Switch runs entirely within a **Tailscale network** (tailnet):

- **XMPP Server (ejabberd)**: Runs on the dev machine, listens on its Tailscale IP
- **User's XMPP Client**: Connects via Tailscale - no port forwarding or public exposure needed
- **All bots**: Connect locally to ejabberd on the same machine

This means:
- You need ejabberd installed and configured on the dev machine
- Your XMPP client connects to the machine's Tailscale IP (e.g., `100.x.x.x`)
- Everything stays private within your tailnet

## Components

## Message Processing (Current)

Switch's session execution is split into a thin XMPP adapter (SessionBot) and a
single-session runtime (SessionRuntime) that owns queueing, cancellation, and
runner orchestration.

### Orchestrator Contacts

Multiple orchestrators, each tied to a specific AI engine:

| Contact | Engine | Model |
|---------|--------|-------|
| `cc@domain` | Claude Code | Opus |
| `oc@domain` | OpenCode | GLM 4.7 |
| `oc-gpt@domain` | OpenCode | GPT 5.2 |
| `oc-glm-zen@domain` | OpenCode | GLM 4.7 (Zen) |
| `oc-gpt-or@domain` | OpenCode | GPT 5.2 (OpenRouter) |
| `oc-kimi-coding@domain` | OpenCode | Kimi K2.5 (Kimi for Coding) |

Send any message to an orchestrator to create a new session using that engine. Each orchestrator handles:

- Session creation with auto-generated names from message content
- Global commands (`/list`, `/kill`, `/recent`, `/help`)

### Session Bots (`session-name@domain`)

One bot per conversation. Each session:

- Has its own XMPP account (created dynamically via ejabberdctl)
- Maintains conversation context with the AI backend
- Can switch between OpenCode and Claude engines
- Tracks costs, tokens, and tool usage

### Session Manager

Coordinates all bots:

- Starts/stops session bots
- Restores active sessions on restart
- Manages XMPP account lifecycle

### Lifecycle (Source of Truth)

Session create/kill semantics are centralized in:

- `src/lifecycle/sessions.py`

Dispatcher bots, session bots, and shell scripts should delegate to this module
to avoid drift.

## Data Flow

1. **New Session**: Message to orchestrator (cc/oc/oc-gpt) → slugify name → create XMPP account → spawn SessionBot with engine config → process first message

2. **Continuing Session**: Message to session contact → SessionBot receives → run AI backend → stream response back

3. **Session Output**: All AI output logged to `~/switch/output/<session>.log` for debugging and `/peek` command

## Database Schema

SQLite database (`~/switch/sessions.db`) stores:

```sql
sessions (
    name TEXT PRIMARY KEY,        -- e.g., "fix-auth-bug"
    xmpp_jid TEXT,                -- e.g., "fix-auth-bug@domain"
    xmpp_password TEXT,
    claude_session_id TEXT,       -- For resuming Claude conversations
    opencode_session_id TEXT,     -- For resuming OpenCode conversations
    active_engine TEXT,           -- "opencode" or "claude"
    model_id TEXT,                -- OpenCode model selection
    status TEXT                   -- "active" or "closed"
)
```

## AI Backends

### OpenCode

- Runs `opencode run --format json`
- Parses streaming JSON events
- Supports model selection and reasoning modes
- Tracks detailed token usage

### Claude Code

- Runs `claude -p --output-format stream-json`
- Parses streaming JSON events
- Uses Opus model
- Supports session resumption

## Ralph Loop

Autonomous iteration system for long-running tasks:

```
/ralph 20 Fix all type errors --wait 5
```

Runs the AI in a loop until:
- Max iterations reached
- Completion promise detected in output
- Manual cancellation via `/ralph-cancel`
- Wait interval between iterations (default ~0.03 min, configurable with `--wait`)
