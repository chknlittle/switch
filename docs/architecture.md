# Architecture

## Overview

Switch creates a chat-based interface for AI coding assistants. Each conversation session becomes a separate XMPP contact, allowing you to manage multiple concurrent AI conversations from any XMPP client (Conversations, Gajim, Dino, etc.).

The codebase lives at `~/switch`. AI agents working on this project should reference `~/switch/AGENTS.md` for conventions and `~/switch/memory/` for persistent context.

<!-- DIAGRAM:system -->
<!-- (auto-generated by scripts/sync-diagrams.py; edit docs/diagrams/system.mermaid) -->
```mermaid
flowchart LR
    subgraph User["User Devices"]
        Client["XMPP Client<br/>(Conversations, Gajim, etc.)"]
    end

    subgraph Tailnet["Tailscale Network"]
        subgraph DevBox["Development Machine"]
            XMPP["ejabberd<br/>(XMPP Server)"]

            subgraph Orchestrators["Orchestrator Contacts"]
                direction TB
                CC["cc@...<br/>(Claude Code)"]
                OC["oc@...<br/>(OpenCode GLM 4.7 Heretic)"]
                OCGPT["oc-gpt@...<br/>(OpenCode GPT 5.2)"]
            end

            Sessions["Session Bots<br/>(task-name@...)"]

            subgraph Engines["AI CLIs"]
                direction TB
                OpenCode["OpenCode CLI"]
                Claude["Claude CLI"]
            end
        end
    end

    Client <-->|"Tailscale IP"| XMPP
    XMPP <--> CC
    XMPP <--> OC
    XMPP <--> OCGPT
    XMPP <--> Sessions
    Sessions --> OpenCode
    Sessions --> Claude

    classDef orchestrator fill:#f5f5e8,stroke:#8a7d60,color:#2c2c2c;
    class CC,OC,OCGPT orchestrator;
```
<!-- /DIAGRAM:system -->

<!-- DIAGRAM:session-message-flow -->
<!-- (auto-generated by scripts/sync-diagrams.py; edit docs/diagrams/session-message-flow.mermaid) -->
```mermaid
flowchart TB
  %% Switch: big-block session architecture

  User["User XMPP Client"]
  XMPP["ejabberd (XMPP)"]
  Orchestrators["Orchestrators<br/>(DispatcherBot + SessionManager + lifecycle)"]

  Adapter["Session XMPP Adapter<br/>(SessionBot + parsing + typing + event sink)"]
  Core["[Q] Session Core<br/>(SessionRuntime)<br/>- queue + cancel<br/>- run (messages + Ralph)"]

  subgraph Runners["Runners"]
    direction TB
    Local["Local runner<br/>(ClaudeRunner + tools)"]
    Remote["Remote runner<br/>(OpenCodeRunner + OpenCode server)"]
  end

  Storage["Storage<br/>(sessions.db + attachments)"]

  %% High-level flows
  User <--> XMPP
  XMPP -->|"orchestrator messages"| Orchestrators
  Orchestrators --> Storage

  XMPP -->|"session message"| Adapter
  Adapter -->|enqueue| Core
  Core -->|persist state/messages| Storage

  Core -->|execute| Local
  Core -->|execute| Remote

  %% Outbound path
  Core -->|emit OutboundMessage/ProcessingChanged| Adapter
  Adapter -->|send XMPP| XMPP

  %% Cancellation (single choke point)
  Adapter -.->|cancel| Core

  classDef core stroke:#111,stroke-width:2px,fill:#f8f8f8,color:#111;
  class Core core;
```
<!-- /DIAGRAM:session-message-flow -->

<!-- DIAGRAM:opencode-runner -->
<!-- (auto-generated by scripts/sync-diagrams.py; edit docs/diagrams/opencode-runner.mermaid) -->
```mermaid
flowchart TB
  %% OpenCode path (big blocks)

  Core["Session Core<br/>(SessionRuntime)"]
  Adapter["Session XMPP Adapter<br/>(SessionBot + event sink)"]

  OpenCodeRunner["OpenCodeRunner<br/>(HTTP + SSE)"]
  OpenCodeServer["External OpenCode server"]

  %% Main execution
  Core -->|run prompt| OpenCodeRunner
  OpenCodeRunner <--> |HTTP + SSE| OpenCodeServer

  %% Questions are bridged through the adapter
  OpenCodeRunner -->|question| Core
  Core -->|emit question meta| Adapter
  Adapter -->|user reply| Core
  Core -->|answer| OpenCodeRunner

  %% Results
  OpenCodeRunner -->|stream events| Core
  Core -->|emit OutboundMessage| Adapter
```
<!-- /DIAGRAM:opencode-runner -->

To keep this diagram consistent across docs, update `docs/diagrams/system.mermaid` and run:

```bash
python3 scripts/sync-diagrams.py
```

## Network Topology

Switch runs entirely within a **Tailscale network** (tailnet):

- **XMPP Server (ejabberd)**: Runs on the dev machine, listens on its Tailscale IP
- **User's XMPP Client**: Connects via Tailscale - no port forwarding or public exposure needed
- **All bots**: Connect locally to ejabberd on the same machine

This means:
- You need ejabberd installed and configured on the dev machine
- Your XMPP client connects to the machine's Tailscale IP (e.g., `100.x.x.x`)
- Everything stays private within your tailnet

## Components

## Message Processing (Current)

Think of Switch as 3 big blocks:

1) XMPP adapter: `SessionBot` (parsing + typing + XMPP send)
2) Session core: `SessionRuntime` (queue + cancel + run + Ralph)
3) Runners: local (Claude) and remote (OpenCode)

The core never talks XMPP directly; it emits outbound events to an EventSink
implemented by the XMPP adapter.

### Orchestrator Contacts

Multiple orchestrators, each tied to a specific AI engine:

| Contact | Engine | Model |
|---------|--------|-------|
| `cc@domain` | Claude Code | Opus |
| `oc@domain` | OpenCode | GLM 4.7 Heretic |
| `oc-gpt@domain` | OpenCode | GPT 5.2 |
| `oc-glm-zen@domain` | OpenCode | GLM 4.7 (Zen) |
| `oc-gpt-or@domain` | OpenCode | GPT 5.2 (OpenRouter) |
| `oc-kimi-coding@domain` | OpenCode | Kimi K2.5 (Kimi for Coding) |

Send any message to an orchestrator to create a new session using that engine. Each orchestrator handles:

- Session creation with auto-generated names from message content
- Global commands (`/list`, `/kill`, `/recent`, `/help`)

### Session Bots (`session-name@domain`)

One bot per conversation. Each session:

- Has its own XMPP account (created dynamically via ejabberdctl)
- Maintains conversation context with the AI backend
- Can switch between OpenCode and Claude engines
- Tracks costs, tokens, and tool usage

### Session Manager

Coordinates all bots:

- Starts/stops session bots
- Restores active sessions on restart
- Manages XMPP account lifecycle

### Lifecycle (Source of Truth)

Session create/kill semantics are centralized in:

- `src/lifecycle/sessions.py`

Dispatcher bots, session bots, and shell scripts should delegate to this module
to avoid drift.

## Data Flow

1. **New Session**: Message to orchestrator (cc/oc/oc-gpt) → slugify name → create XMPP account → spawn SessionBot with engine config → process first message

2. **Continuing Session**: Message to session contact → SessionBot receives → run AI backend → stream response back

3. **Session Output**: All AI output logged to `~/switch/output/<session>.log` for debugging and `/peek` command

## Database Schema

SQLite database (`~/switch/sessions.db`) stores:

```sql
sessions (
    name TEXT PRIMARY KEY,        -- e.g., "fix-auth-bug"
    xmpp_jid TEXT,                -- e.g., "fix-auth-bug@domain"
    xmpp_password TEXT,
    claude_session_id TEXT,       -- For resuming Claude conversations
    opencode_session_id TEXT,     -- For resuming OpenCode conversations
    active_engine TEXT,           -- "opencode" or "claude"
    model_id TEXT,                -- OpenCode model selection
    status TEXT                   -- "active" or "closed"
)
```

## AI Backends

### OpenCode

- Runs `opencode run --format json`
- Parses streaming JSON events
- Supports model selection and reasoning modes
- Tracks detailed token usage

### Claude Code

- Runs `claude -p --output-format stream-json`
- Parses streaming JSON events
- Uses Opus model
- Supports session resumption

## Ralph Loop

Autonomous iteration system for long-running tasks:

```
/ralph 20 Fix all type errors --wait 5
```

Runs the AI in a loop until:
- Max iterations reached
- Completion promise detected in output
- Manual cancellation via `/ralph-cancel`
- Wait interval between iterations (default ~0.03 min, configurable with `--wait`)
